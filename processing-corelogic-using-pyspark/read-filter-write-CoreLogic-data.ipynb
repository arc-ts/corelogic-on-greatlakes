{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67d5aec",
   "metadata": {},
   "source": [
    "# Processing the CoreLogic Data using PySpark\n",
    "\n",
    "In this Jupyter notebook, we demonstrate how you can process the CoreLogic data using PySpark. \n",
    "\n",
    "In particular, we will show you how to:\n",
    "* import the data, \n",
    "* explore rows and columns, \n",
    "* filter for a given location, \n",
    "* inspect the data for missing and erroneous information, \n",
    "* correct data errors,\n",
    "* and write a subset of the data to a csv file for later use. \n",
    "\n",
    "This [PySpark cheat sheet](http://datacamp-community-prod.s3.amazonaws.com/acfa4325-1d43-4542-8ce4-bea2d287db10) provides a great overview of available PySpark functionality. \n",
    "\n",
    "The notebook was created using a 'Jupyter + Spark Basic session' in [Open on Demand](https://arc.umich.edu/open-ondemand/) (OOD) on [Great Lakes](https://arc.umich.edu/greatlakes/) (GL). This automatically initializes Spark in the background.\n",
    "\n",
    "If you are not running the notebook using OOD on GL, you will most likely have to make sure PySpark is installed on your system and then initialize it by typing \n",
    "\n",
    "```from pyspark import SparkContext```\n",
    "\n",
    "```sc = SparkContext(master = 'local[2]')```\n",
    "\n",
    "If you encounter any errors or have questions about this Jupyter notebook, or if you would like us to add another PySpark example using the CoreLogic data, feel free to reach out to [Armand Burks](mailto:arburks@umich.edu) and [Jule Kr√ºger](mailto:julianek@umich.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc16a3e",
   "metadata": {},
   "source": [
    "## Importing the CoreLogic data with PySpark\n",
    "\n",
    "The CoreLogic data are stored in a Turbo volume on the ```/nfs``` drive. To get access, you will need to sign a Memorandum of Understanding (MOU) with the University of Michigan Library. For more information about this, see [here](https://github.com/arc-ts/corelogic-on-greatlakes/tree/main/intro-to-corelogic-data). To execute this notebook, you will have to be granted access to the CoreLogic data on Turbo.\n",
    "\n",
    "The raw data come in three separate files: deeds (28GB), foreclosures (6GB), and taxes (24GB). [CSCAR](https://cscar.research.umich.edu/) pre-processed the CoreLogic data and stored each raw file in 100 separate partitions. You can read more about this methodology in ```nfs/turbo/lib-data-corelogic/Docs/cscar_data.txt```.\n",
    "\n",
    "We are going to work with the pre-processed data to improve import speeds. Let's store the paths to the pre-processed partitioned files in three separate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce474a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_path_fcl = \"/nfs/turbo/lib-data-corelogic/Data/fcl/*.gz\"\n",
    "turbo_path_deed = \"/nfs/turbo/lib-data-corelogic/Data/deed/*.gz\"\n",
    "turbo_path_tax = \"/nfs/turbo/lib-data-corelogic/Data/tax/*.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ba4b9",
   "metadata": {},
   "source": [
    "The following command imports a set of partitioned CoreLogic data file into a dataframe (df). You can switch between foreclosures, deeds, and taxes by choosing the relevant path accordingly. In each text file, the pipe ```|``` was used as a delimiter and is set  in the ```sep``` argument as such.\n",
    "\n",
    "__A note on import speeds__: Because of their size, it takes a little while to read in each partitioned data file collection. Importing the raw data files takes much longer. Using the pre-processed data from CSCAR, which distributes the data across 100 partitions, greatly improves import speeds as Spark can spread computation across multiple cores.\n",
    "\n",
    "Let's work with the deed data for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5904b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(turbo_path_deed, header=True, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29b5d2",
   "metadata": {},
   "source": [
    "(A small note on reading in the data: You could set the ```inferSchema=True``` argument, which would make Python infer the column type. The drawback of this is that FIPS and ZIP codes that start with a `0` have the leading `0` removed in the creation of an integer variable. We choose to keep ```inferSchema=False```, the default argumentn to avoid this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3978f9af",
   "metadata": {},
   "source": [
    "## Exploring the CoreLogic data\n",
    "\n",
    "First, we want to get a basic idea of the CoreLogic data. What are the columns and what types of values do they contain? The .printSchema() method prints the data type (integer, string, double) for each column in the dataset. \n",
    "\n",
    "Note that the ```double``` data type is unique to Spark. It represents double precision floats [[source](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.DoubleType.html)]. Also, ```nullable = true``` means that a given column can accept missing (```null```) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eebc90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FIPS: string (nullable = true)\n",
      " |-- APN (Parcel Number) (unformatted): string (nullable = true)\n",
      " |-- PCL ID IRIS FORMATTED: string (nullable = true)\n",
      " |-- APN SEQUENCE NUMBER: string (nullable = true)\n",
      " |-- PENDING RECORD INDICATOR: string (nullable = true)\n",
      " |-- CORPORATE INDICATOR: string (nullable = true)\n",
      " |-- OWNER FULL NAME: string (nullable = true)\n",
      " |-- OWNER 1 LAST NAME: string (nullable = true)\n",
      " |-- OWNER 1 FIRST NAME & M I: string (nullable = true)\n",
      " |-- OWNER 2 LAST NAME: string (nullable = true)\n",
      " |-- OWNER 2 FIRST NAME & MI: string (nullable = true)\n",
      " |-- OWNER ETAL INDICATOR: string (nullable = true)\n",
      " |-- C/O NAME: string (nullable = true)\n",
      " |-- OWNER RELATIONSHIP RIGHTS CODE: string (nullable = true)\n",
      " |-- OWNER RELATIONSHIP TYPE: string (nullable = true)\n",
      " |-- PARTIAL INTEREST INDICATOR: string (nullable = true)\n",
      " |-- ABSENTEE OWNER STATUS: string (nullable = true)\n",
      " |-- PROPERTY LEVEL LATITUDE: string (nullable = true)\n",
      " |-- PROPERTY LEVEL LONGITUDE: string (nullable = true)\n",
      " |-- SITUS HOUSE NUMBER PREFIX: string (nullable = true)\n",
      " |-- SITUS HOUSE NUMBER: string (nullable = true)\n",
      " |-- SITUS HOUSE NUMBER SUFFIX: string (nullable = true)\n",
      " |-- SITUS DIRECTION: string (nullable = true)\n",
      " |-- SITUS STREET NAME: string (nullable = true)\n",
      " |-- SITUS MODE: string (nullable = true)\n",
      " |-- SITUS QUADRANT: string (nullable = true)\n",
      " |-- SITUS APARTMENT UNIT: string (nullable = true)\n",
      " |-- SITUS CITY: string (nullable = true)\n",
      " |-- SITUS STATE: string (nullable = true)\n",
      " |-- SITUS ZIP CODE: string (nullable = true)\n",
      " |-- SITUS CARRIER CODE: string (nullable = true)\n",
      " |-- MAILING HOUSE NUMBER PREFIX: string (nullable = true)\n",
      " |-- MAILING HOUSE NUMBER: string (nullable = true)\n",
      " |-- MAILING HOUSE NUMBER SUFFIX: string (nullable = true)\n",
      " |-- MAILING DIRECTION: string (nullable = true)\n",
      " |-- MAILING STREET NAME: string (nullable = true)\n",
      " |-- MAILING MODE: string (nullable = true)\n",
      " |-- MAILING QUADRANT: string (nullable = true)\n",
      " |-- MAILING APARTMENT UNIT: string (nullable = true)\n",
      " |-- MAILING PROPERTY CITY: string (nullable = true)\n",
      " |-- MAILING PROPERTY STATE: string (nullable = true)\n",
      " |-- MAILING PROPERTY ADDRESS ZIP CODE: string (nullable = true)\n",
      " |-- MAILING CARRIER CODE: string (nullable = true)\n",
      " |-- BATCH-ID: string (nullable = true)\n",
      " |-- BATCH-SEQ: string (nullable = true)\n",
      " |-- MULTI APN: string (nullable = true)\n",
      " |-- SELLER LAST NAME: string (nullable = true)\n",
      " |-- SELLER FIRST NAME: string (nullable = true)\n",
      " |-- SELLER NAME 1: string (nullable = true)\n",
      " |-- SELLER NAME 2: string (nullable = true)\n",
      " |-- SALE CODE: string (nullable = true)\n",
      " |-- SALE AMOUNT: string (nullable = true)\n",
      " |-- SALE DATE (YYYYMMDD): string (nullable = true)\n",
      " |-- RECORDING DATE (YYYYMMDD): string (nullable = true)\n",
      " |-- DOCUMENT TYPE: string (nullable = true)\n",
      " |-- TRANSACTION TYPE: string (nullable = true)\n",
      " |-- DOCUMENT NUMBER: string (nullable = true)\n",
      " |-- BOOK/PAGE (6x6): string (nullable = true)\n",
      " |-- LENDER FULL NAME: string (nullable = true)\n",
      " |-- LENDER LAST NAME: string (nullable = true)\n",
      " |-- LENDER FIRST NAME: string (nullable = true)\n",
      " |-- LENDER ADDRESS: string (nullable = true)\n",
      " |-- LENDER CITY: string (nullable = true)\n",
      " |-- LENDER ST: string (nullable = true)\n",
      " |-- LENDER ZIP: string (nullable = true)\n",
      " |-- LENDER COMPANY CODE: string (nullable = true)\n",
      " |-- TITLE COMPANY NAME: string (nullable = true)\n",
      " |-- TITLE COMPANY CODE: string (nullable = true)\n",
      " |-- MORTGAGE AMOUNT: string (nullable = true)\n",
      " |-- MORTGAGE DATE: string (nullable = true)\n",
      " |-- MORTGAGE INTEREST RATE: string (nullable = true)\n",
      " |-- MORTGAGE LOAN TYPE CODE: string (nullable = true)\n",
      " |-- MORTGAGE DEED TYPE: string (nullable = true)\n",
      " |-- MORTGAGE TERM CODE: string (nullable = true)\n",
      " |-- MORTGAGE TERM: string (nullable = true)\n",
      " |-- MORTGAGE DUE DATE: string (nullable = true)\n",
      " |-- MORTGAGE ASSUMPTION AMOUNT: string (nullable = true)\n",
      " |-- MTG SEQ NUMBER: string (nullable = true)\n",
      " |-- PRI-CAT-CODE: string (nullable = true)\n",
      " |-- MTG SEC CAT CODES 1X10: string (nullable = true)\n",
      " |-- DEED SEC CAT CODES 2X10: string (nullable = true)\n",
      " |-- OWNERSHIP TRANSFER PERCENTAGE: string (nullable = true)\n",
      " |-- LAND USE: string (nullable = true)\n",
      " |-- PROPERTY INDICATOR: string (nullable = true)\n",
      " |-- SELLER CARRY BACK: string (nullable = true)\n",
      " |-- INTER FAMILY: string (nullable = true)\n",
      " |-- PRIVATE PARTY LENDER: string (nullable = true)\n",
      " |-- MORTGAGE INTEREST RATE TYPE: string (nullable = true)\n",
      " |-- CONSTRUCTION LOAN: string (nullable = true)\n",
      " |-- RESALE/NEW CONSTRUCTION: string (nullable = true)\n",
      " |-- FORECLOSURE: string (nullable = true)\n",
      " |-- CASH/MORTGAGE PURCHASE: string (nullable = true)\n",
      " |-- EQUITY FLAG: string (nullable = true)\n",
      " |-- REFI FLAG: string (nullable = true)\n",
      " |-- RESIDENTIAL MODEL INDICATOR: string (nullable = true)\n",
      " |-- ADD/CHANGE FIELD: string (nullable = true)\n",
      " |-- FILLER: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3058a25",
   "metadata": {},
   "source": [
    "We can calculate how many rows and columns there are in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951a0324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367782480, 97)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns))) ## print number of rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e508e",
   "metadata": {},
   "source": [
    "We can print a list of the column names like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3ac646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FIPS',\n",
       " 'APN (Parcel Number) (unformatted)',\n",
       " 'PCL ID IRIS FORMATTED',\n",
       " 'APN SEQUENCE NUMBER',\n",
       " 'PENDING RECORD INDICATOR',\n",
       " 'CORPORATE INDICATOR',\n",
       " 'OWNER FULL NAME',\n",
       " 'OWNER 1 LAST NAME',\n",
       " 'OWNER 1 FIRST NAME & M I',\n",
       " 'OWNER 2 LAST NAME',\n",
       " 'OWNER 2 FIRST NAME & MI',\n",
       " 'OWNER ETAL INDICATOR',\n",
       " 'C/O NAME',\n",
       " 'OWNER RELATIONSHIP RIGHTS CODE',\n",
       " 'OWNER RELATIONSHIP TYPE',\n",
       " 'PARTIAL INTEREST INDICATOR',\n",
       " 'ABSENTEE OWNER STATUS',\n",
       " 'PROPERTY LEVEL LATITUDE',\n",
       " 'PROPERTY LEVEL LONGITUDE',\n",
       " 'SITUS HOUSE NUMBER PREFIX',\n",
       " 'SITUS HOUSE NUMBER',\n",
       " 'SITUS HOUSE NUMBER SUFFIX',\n",
       " 'SITUS DIRECTION',\n",
       " 'SITUS STREET NAME',\n",
       " 'SITUS MODE',\n",
       " 'SITUS QUADRANT',\n",
       " 'SITUS APARTMENT UNIT',\n",
       " 'SITUS CITY',\n",
       " 'SITUS STATE',\n",
       " 'SITUS ZIP CODE',\n",
       " 'SITUS CARRIER CODE',\n",
       " 'MAILING HOUSE NUMBER PREFIX',\n",
       " 'MAILING HOUSE NUMBER',\n",
       " 'MAILING HOUSE NUMBER SUFFIX',\n",
       " 'MAILING DIRECTION',\n",
       " 'MAILING STREET NAME',\n",
       " 'MAILING MODE',\n",
       " 'MAILING QUADRANT',\n",
       " 'MAILING APARTMENT UNIT',\n",
       " 'MAILING PROPERTY CITY',\n",
       " 'MAILING PROPERTY STATE',\n",
       " 'MAILING PROPERTY ADDRESS ZIP CODE',\n",
       " 'MAILING CARRIER CODE',\n",
       " 'BATCH-ID',\n",
       " 'BATCH-SEQ',\n",
       " 'MULTI APN',\n",
       " 'SELLER LAST NAME',\n",
       " 'SELLER FIRST NAME',\n",
       " 'SELLER NAME 1',\n",
       " 'SELLER NAME 2',\n",
       " 'SALE CODE',\n",
       " 'SALE AMOUNT',\n",
       " 'SALE DATE (YYYYMMDD)',\n",
       " 'RECORDING DATE (YYYYMMDD)',\n",
       " 'DOCUMENT TYPE',\n",
       " 'TRANSACTION TYPE',\n",
       " 'DOCUMENT NUMBER',\n",
       " 'BOOK/PAGE (6x6)',\n",
       " 'LENDER FULL NAME',\n",
       " 'LENDER LAST NAME',\n",
       " 'LENDER FIRST NAME',\n",
       " 'LENDER ADDRESS',\n",
       " 'LENDER CITY',\n",
       " 'LENDER ST',\n",
       " 'LENDER ZIP',\n",
       " 'LENDER COMPANY CODE',\n",
       " 'TITLE COMPANY NAME',\n",
       " 'TITLE COMPANY CODE',\n",
       " 'MORTGAGE AMOUNT',\n",
       " 'MORTGAGE DATE',\n",
       " 'MORTGAGE INTEREST RATE',\n",
       " 'MORTGAGE LOAN TYPE CODE',\n",
       " 'MORTGAGE DEED TYPE',\n",
       " 'MORTGAGE TERM CODE',\n",
       " 'MORTGAGE TERM',\n",
       " 'MORTGAGE DUE DATE',\n",
       " 'MORTGAGE ASSUMPTION AMOUNT',\n",
       " 'MTG SEQ NUMBER',\n",
       " 'PRI-CAT-CODE',\n",
       " 'MTG SEC CAT CODES 1X10',\n",
       " 'DEED SEC CAT CODES 2X10',\n",
       " 'OWNERSHIP TRANSFER PERCENTAGE',\n",
       " 'LAND USE',\n",
       " 'PROPERTY INDICATOR',\n",
       " 'SELLER CARRY BACK',\n",
       " 'INTER FAMILY',\n",
       " 'PRIVATE PARTY LENDER',\n",
       " 'MORTGAGE INTEREST RATE TYPE',\n",
       " 'CONSTRUCTION LOAN',\n",
       " 'RESALE/NEW CONSTRUCTION',\n",
       " 'FORECLOSURE',\n",
       " 'CASH/MORTGAGE PURCHASE',\n",
       " 'EQUITY FLAG',\n",
       " 'REFI FLAG',\n",
       " 'RESIDENTIAL MODEL INDICATOR',\n",
       " 'ADD/CHANGE FIELD',\n",
       " 'FILLER']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44557b99",
   "metadata": {},
   "source": [
    "To better understand the columns, we can print summary statistics for those of type ```integer``` and ```double```.\n",
    "\n",
    "The 'FIPS' column designates the Federal Information Processing Standard county code. It contains five digits. As we can see in the summary statistics below, the 'FIPS' column contains errors as the minimum value of 1001 only contains four digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b55f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              FIPS|\n",
      "+-------+------------------+\n",
      "|  count|         367782480|\n",
      "|   mean| 25295.95461476577|\n",
      "| stddev|16730.499490625767|\n",
      "|    min|              1001|\n",
      "|    max|             97201|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['FIPS']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd540f",
   "metadata": {},
   "source": [
    "A statistical summary of the FIPS column is not meaningful as it represents a discrete/categorical variable (ordinal scale of measurement). \n",
    "\n",
    "Let's look at a column of type ```double```. The 'MORTGAGE AMOUNT' represents a continuous variable. As you can see, the average mortgage in the CoreLogic data was about $800K. Some properties had no mortgage taken on them (minimum value = 0). The largest mortgage (maximum value) was USD 33 billion 300 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6ba760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|    MORTGAGE AMOUNT|\n",
      "+-------+-------------------+\n",
      "|  count|          111059401|\n",
      "|   mean|  799771.0156008194|\n",
      "| stddev|2.141949398883503E7|\n",
      "|    min|                0.0|\n",
      "|    max|            3.33E10|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['MORTGAGE AMOUNT']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9203f5a",
   "metadata": {},
   "source": [
    "Let's look at one more variable of interest, the sale amount of a property. This variable is interesting because it is stored as a ```string```. While it should be numerical, this means it must contain some type of non-numerical values. As we can see below, the maximum value is 'U'. When we move to a data cleaning step, we would probably want to set non-numerical values in this column to missing (```null```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "360e045f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|         SALE AMOUNT|\n",
      "+-------+--------------------+\n",
      "|  count|           213239914|\n",
      "|   mean|    418105.188683447|\n",
      "| stddev|2.5857146238130517E7|\n",
      "|    min|                 .01|\n",
      "|    max|                   U|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['SALE AMOUNT']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c22de",
   "metadata": {},
   "source": [
    "We might also be interested in the range of unique values of categorical variables. Let's print the unique values of states designated by the 'SITUS STATE' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00ad8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.select('SITUS STATE').distinct().rdd.map(lambda r: r[0]).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86990683",
   "metadata": {},
   "source": [
    "The SITUS STATE column contains 53 unique values, which is unexpected. There should be 50 states plus Washington, DC. Let's create a frequency table of the column values to get a better idea about this variable. We will sort the table in descending order of state counts. We will set ```n=53``` in the show() method to print all rows in the table. The two additional values are ```null``` (the amount of missing values in the SITUS STATE column). The additional territory captured as a state here is VI, the Virgin Islands.\n",
    "\n",
    "TODO: sort this column by count in ascending or descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78155564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|SITUS STATE|   count|\n",
      "+-----------+--------+\n",
      "|         SC| 6311502|\n",
      "|         AZ|12006118|\n",
      "|         LA| 2497956|\n",
      "|         MN| 4267855|\n",
      "|         NJ| 7320302|\n",
      "|         DC|  457645|\n",
      "|         OR| 4767128|\n",
      "|         VA| 7827533|\n",
      "|       null|35371569|\n",
      "|         RI|  465933|\n",
      "|         WY|  300540|\n",
      "|         KY| 3018343|\n",
      "|         NH|  559467|\n",
      "|         MI| 8638900|\n",
      "|         NV| 4712444|\n",
      "|         WI| 3864221|\n",
      "|         ID| 1138025|\n",
      "|         CA|52167596|\n",
      "|         CT| 2513164|\n",
      "|         NE| 1365483|\n",
      "|         MT| 1289606|\n",
      "|         NC| 9686809|\n",
      "|         VT|  329881|\n",
      "|         MD| 6525203|\n",
      "|         DE|  905431|\n",
      "|         MO| 6496410|\n",
      "|         VI|   20620|\n",
      "|         IL|11947950|\n",
      "|         ME|  614182|\n",
      "|         WA| 8104844|\n",
      "|         ND|  426858|\n",
      "|         MS| 2978654|\n",
      "|         AL| 4379161|\n",
      "|         IN| 4394358|\n",
      "|         OH|13347704|\n",
      "|         TN| 8638649|\n",
      "|         IA| 1982068|\n",
      "|         NM| 1546001|\n",
      "|         PA|12254911|\n",
      "|         SD|  318106|\n",
      "|         NY|10456027|\n",
      "|         TX|21674192|\n",
      "|         WV| 2374639|\n",
      "|         GA|11148302|\n",
      "|         MA| 4876134|\n",
      "|         KS| 2348984|\n",
      "|         FL|35281257|\n",
      "|         CO| 8112459|\n",
      "|         AK|  428840|\n",
      "|         AR| 4378459|\n",
      "|         OK| 5217718|\n",
      "|         UT| 3154019|\n",
      "|         HI| 2572320|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('SITUS STATE').count().show(n=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b9e0e",
   "metadata": {},
   "source": [
    "## What amount of information is missing in the CoreLogic data?\n",
    "\n",
    "It is important to know for columns of interest how many missing values they contain. Information on data missingness guides decisions on what needs to be done with affected rows. Can rows with missing information easily be dropped? Or, do we need to try to fill in missing values conditional on information in other columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d157f56",
   "metadata": {},
   "source": [
    "Suppose we wanted to filter the CoreLogic data based on location. Our goal will be to create a subset of the data that only contains rows relating to Detroit, Michigan. \n",
    "\n",
    "Let's print a select few rows and columns of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22b0d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+--------------+\n",
      "| FIPS|SITUS CITY|SITUS STATE|SITUS ZIP CODE|\n",
      "+-----+----------+-----------+--------------+\n",
      "|12099|      null|       null|          null|\n",
      "|17097|      null|       null|          null|\n",
      "|97200|      null|       null|          null|\n",
      "|97200|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|17097|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "+-----+----------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('FIPS', 'SITUS CITY', 'SITUS STATE', 'SITUS ZIP CODE').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a86b461",
   "metadata": {},
   "source": [
    "Notice how there are many rows containing columns with null values. We will remove rows that hvae nulls in the columns of interest for the later analysis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df7ea2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"FIPS\",\"SITUS CITY\", \"SITUS STATE\", \"SITUS ZIP CODE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a1f3f",
   "metadata": {},
   "source": [
    "Now let's see how many rows we have out of the original 367,782,480:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef93115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311359183"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cde04",
   "metadata": {},
   "source": [
    "Let's assume we wanted to filter the CoreLogic data only for Wayne county, MI. The FIPS code for Wayne county is '26163' ([source](https://mi.postcodebase.com/county/26163))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f4902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WayneCsubset = df.filter(df.FIPS==26163)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2467d87",
   "metadata": {},
   "source": [
    "Let's print a few rows and columns of the subset. As you can see, we are only dealing with Wayne county now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb6648b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+--------------+\n",
      "| FIPS|SITUS CITY|SITUS STATE|SITUS ZIP CODE|\n",
      "+-----+----------+-----------+--------------+\n",
      "|26163|   DETROIT|         MI|     482013148|\n",
      "|26163|   DETROIT|         MI|     482013148|\n",
      "|26163|   DETROIT|         MI|     482013148|\n",
      "|26163|   DETROIT|         MI|     482013148|\n",
      "|26163|   DETROIT|         MI|     482012463|\n",
      "|26163|   DETROIT|         MI|         48202|\n",
      "|26163|   DETROIT|         MI|         48202|\n",
      "|26163|   DETROIT|         MI|         48202|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|         48202|\n",
      "|26163|   DETROIT|         MI|     482021302|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "+-----+----------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "WayneCsubset.select('FIPS', 'SITUS CITY', 'SITUS STATE', 'SITUS ZIP CODE').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb7ce7",
   "metadata": {},
   "source": [
    "How many rows are in the Wayne county subset? Use the count() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01514600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2132959"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WayneCsubset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a766ab9",
   "metadata": {},
   "source": [
    "There are many different cities within Wayne county. Let's get a list of all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f61109f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SITUS CITY='LINCOLN PARK'),\n",
       " Row(SITUS CITY='MELVINDALE'),\n",
       " Row(SITUS CITY='NORTHVILLE'),\n",
       " Row(SITUS CITY='TRENTON'),\n",
       " Row(SITUS CITY='YPSILANTI'),\n",
       " Row(SITUS CITY='BELLEVILLE'),\n",
       " Row(SITUS CITY='OAK PARK'),\n",
       " Row(SITUS CITY='RIVERVIEW'),\n",
       " Row(SITUS CITY='GROSSE POINTE WOODS'),\n",
       " Row(SITUS CITY='FLAT ROCK'),\n",
       " Row(SITUS CITY='GROSSE ILE'),\n",
       " Row(SITUS CITY='GROSSE POINTE PARK'),\n",
       " Row(SITUS CITY='WARREN'),\n",
       " Row(SITUS CITY='GIBRALTAR'),\n",
       " Row(SITUS CITY='GROSSE POINTE'),\n",
       " Row(SITUS CITY='MONROE'),\n",
       " Row(SITUS CITY='WYANDOTTE'),\n",
       " Row(SITUS CITY='HIGHLAND'),\n",
       " Row(SITUS CITY='WOODHAVEN'),\n",
       " Row(SITUS CITY='INKSTER'),\n",
       " Row(SITUS CITY='SOUTHGATE'),\n",
       " Row(SITUS CITY='SUMPTER TWP'),\n",
       " Row(SITUS CITY='GARDEN CITY'),\n",
       " Row(SITUS CITY='HIGHLAND PARK'),\n",
       " Row(SITUS CITY='DETROIT'),\n",
       " Row(SITUS CITY='FERNDALE'),\n",
       " Row(SITUS CITY='CHELSEA'),\n",
       " Row(SITUS CITY='BROWNSTOWN TWP'),\n",
       " Row(SITUS CITY='NEW HUDSON'),\n",
       " Row(SITUS CITY='LANSING'),\n",
       " Row(SITUS CITY='DEARBORN HEIGHTS'),\n",
       " Row(SITUS CITY='CANTON'),\n",
       " Row(SITUS CITY='DEARBORN'),\n",
       " Row(SITUS CITY='GROSSE POINTE SHORES'),\n",
       " Row(SITUS CITY='ROMULUS'),\n",
       " Row(SITUS CITY='BINGHAM FARMS'),\n",
       " Row(SITUS CITY='LIVONIA'),\n",
       " Row(SITUS CITY='RIVER ROUGE'),\n",
       " Row(SITUS CITY='VAN BUREN TWP'),\n",
       " Row(SITUS CITY='NEW BOSTON'),\n",
       " Row(SITUS CITY='WESTLAND'),\n",
       " Row(SITUS CITY='GROSSE POINTE FARMS'),\n",
       " Row(SITUS CITY='PLYMOUTH'),\n",
       " Row(SITUS CITY='BROWNSTOWN'),\n",
       " Row(SITUS CITY='REDFORD'),\n",
       " Row(SITUS CITY='WAYNE'),\n",
       " Row(SITUS CITY='HARPER WOODS'),\n",
       " Row(SITUS CITY='TAYLOR'),\n",
       " Row(SITUS CITY='CARLETON'),\n",
       " Row(SITUS CITY='ALLEN PARK'),\n",
       " Row(SITUS CITY='SOUTHFIELD'),\n",
       " Row(SITUS CITY='ECORSE'),\n",
       " Row(SITUS CITY='ROCKWOOD'),\n",
       " Row(SITUS CITY='BROWNSTOWN TOWNSHIP'),\n",
       " Row(SITUS CITY='HAMTRAMCK')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WayneCsubset.select('SITUS CITY').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842db83c",
   "metadata": {},
   "source": [
    "Let's create a subset for Detroit only. We will filter using the 'SITUS CITY' variable. This variables designates the city associated with the property address. \n",
    "\n",
    "Note that this is a straightforward filtering method if using the Wayne county subset we created previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fd6c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit = WayneCsubset.filter(WayneCsubset[\"SITUS CITY\"]==\"DETROIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a19a40",
   "metadata": {},
   "source": [
    "If you wanted to create a Detroit subset from the entire dataset, we suggest filtering on 'SITUS CITY' and 'SITUS STATE'. When using the entire dataframe, filtering on 'SITUS CITY' alone could run into city name ambiguity across states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54340b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit2 = df.filter((df[\"SITUS CITY\"]==\"DETROIT\") & (df[\"SITUS STATE\"]==\"MI\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294452ef",
   "metadata": {},
   "source": [
    "How many rows are in the Detroit subset? Depending on the size of the dataframe, count() can take a bit of time to calculate. Therefore, we will save the value to a variable in case we need to use it later on. This can save us some processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2b4aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1129407"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detroitCount = detroit.count()\n",
    "detroitCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed95cf4",
   "metadata": {},
   "source": [
    "Do the two filtering methods yield the same number of rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf449eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1129438"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detroit2Count = detroit2.count()\n",
    "detroit2Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb79a17",
   "metadata": {},
   "source": [
    "We see that we get 2 different results when we filter by (SITUS CITY == \"DETROIT\" and SITUS STATE == \"MI\") versus (FIPS == 26163 and SITUS CITY == \"DETROIT\"). This is because there are multiple FIPS codes where the SITUS CITY is equal to Detroit. Let's see all the FIPS codes for rows with city and state Detroit, MI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3ce289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+-------+\n",
      "| FIPS|SITUS CITY|SITUS STATE|  count|\n",
      "+-----+----------+-----------+-------+\n",
      "|26147|   DETROIT|         MI|      6|\n",
      "|26071|   DETROIT|         MI|      5|\n",
      "|26163|   DETROIT|         MI|1129407|\n",
      "|26061|   DETROIT|         MI|      2|\n",
      "|48039|   DETROIT|         MI|      2|\n",
      "|26069|   DETROIT|         MI|      2|\n",
      "|26035|   DETROIT|         MI|      2|\n",
      "|26115|   DETROIT|         MI|      9|\n",
      "|26099|   DETROIT|         MI|      2|\n",
      "|26161|   DETROIT|         MI|      1|\n",
      "+-----+----------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detroit2.groupBy('FIPS', 'SITUS CITY', 'SITUS STATE').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0e711",
   "metadata": {},
   "source": [
    "The detroit2 dataframe looks like what we are interested in, as it has all the rows from Detroit, MI. Let's write the Detroit data to a new csv file in an ```output/``` folder in our ```home/[uniqname]/``` directory. (Note: You probably need to change this path, depending on where you store this notebook.) By default, Spark writes big data into multiple files to optimize computation times during import and export. This is recommended practice, especially if the data is big, i.e., if it has many rows and/or columns.\n",
    "\n",
    "The below command writes 100 partitions of the Detroit data to the designated folder. \n",
    "\n",
    "_Note_: If you saved data to this path before, you will need to add the argument ```overwrite=True``` to the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ab02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit2.write.csv(\"../../output/corelogic_data_deeds_Detroit_partitioned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1bec64",
   "metadata": {},
   "source": [
    "There is also a way to force the data into one single file. Sometimes, a single file is needed to continue processing the data with other research software. Saving the data into one file is a little risky and might not always work, so caution is advised. \n",
    "\n",
    "The following command combines the data into one core (Caution: it is very slow). If the data does not fit, it will throw an error. _Note_: If you saved data to this path before, you will need to add the argument ```overwrite=True``` to the function call. The overwrite argument would overwrite the previously created ```output/``` directory.\n",
    "\n",
    "Note: You would only need to run this, if you indeed need only one single data file. Many research programs allow you to read in and combine multiple data files into one object. See for example the [glob method in Python](https://docs.python.org/3/library/glob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit2.coalesce(1).write.csv(\"../../output/corelogic_data_deeds_Detroit_singlefile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c58568",
   "metadata": {},
   "source": [
    "Let's say we want to draw and save just a sample of the Detroit data (n~1000) that is small enough to use for writing and testing code for analyzing the Detroit subset. We can use PySpark's DataFrame.sample() method. However, we have to specify a fraction of the dataframe size rather than explicitly the size of the sample, n. Also, we are not guaranteed to get EXACTLY the fraction that we specify, due to the way the sample() function is implemented. Let's see how that works.\n",
    "\n",
    "Since we want about 1000 rows in our sample, we can divide 1000 by detroit2Count to see what fraction that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92f403df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008853960996531018"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleFraction = 1000 / detroit2Count\n",
    "sampleFraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9352aac",
   "metadata": {},
   "source": [
    "Now, let's sample the Detroit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b59e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroitSample = detroit2.sample(fraction=sampleFraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca12fd8",
   "metadata": {},
   "source": [
    "How many records do we have in our sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc78e8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1031"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detroitSample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e58204",
   "metadata": {},
   "source": [
    "Write the results (note that using coalesce(1) can still be quite expensive. Use only if absolutely necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28c18402",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroitSample.write.csv(\"../../output/corelogic_data_deeds_Detroit_sampled_1031_singlefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e446fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

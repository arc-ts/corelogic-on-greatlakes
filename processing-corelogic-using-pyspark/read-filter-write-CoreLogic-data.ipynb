{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67d5aec",
   "metadata": {},
   "source": [
    "# Processing the CoreLogic Data using PySpark\n",
    "\n",
    "In this Jupyter notebook, we demonstrate how you can process the CoreLogic data using PySpark. We will show you how to import the data, explore rows and columns, how to filter for a given location, and how to write a subset of the data to a csv file for later use. This [PySpark cheat sheet](http://datacamp-community-prod.s3.amazonaws.com/acfa4325-1d43-4542-8ce4-bea2d287db10) provides a great overview of available PySpark functionality. \n",
    "\n",
    "The notebook was created using a 'Jupyter + Spark Basic session' in [Open on Demand](https://arc.umich.edu/open-ondemand/) (OOD) on [Great Lakes](https://arc.umich.edu/greatlakes/) (GL). This automatically initializes Spark in the background.\n",
    "\n",
    "If you are not running the notebook using OOD on GL, you will most likely have to make sure PySpark is installed on your system and then initialize it by typing \n",
    "\n",
    "```from pyspark import SparkContext```\n",
    "\n",
    "```sc = SparkContext(master = 'local[2]')```\n",
    "\n",
    "If you encounter any errors or have questions about this Jupyter notebook, or if you would like us to add another PySpark example using the CoreLogic data, feel free to reach out to [Armand Burks](mailto:arburks@umich.edu) and [Jule Kr√ºger](mailto:julianek@umich.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc16a3e",
   "metadata": {},
   "source": [
    "## Importing the CoreLogic data with PySpark\n",
    "\n",
    "The CoreLogic data are stored in a Turbo volume on the ```/nfs``` drive. To get access, you will need to sign a Memorandum of Understanding (MOU) with the University of Michigan Library. For more information about this, see [here](https://github.com/arc-ts/corelogic-on-greatlakes/tree/main/intro-to-corelogic-data). To execute this notebook, you will have to be granted access to the CoreLogic data on Turbo.\n",
    "\n",
    "The raw data come in three separate files: deeds (28GB), foreclosures (6GB), and taxes (24GB). [CSCAR](https://cscar.research.umich.edu/) pre-processed the CoreLogic data and stored each raw file in 100 separate partitions. You can read more about this methodology in ```nfs/turbo/lib-data-corelogic/Docs/cscar_data.txt```.\n",
    "\n",
    "We are going to work with the pre-processed data to improve import speeds. Let's store the paths to the pre-processed partitioned files in three separate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce474a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_path_fcl = \"/nfs/turbo/lib-data-corelogic/Data/fcl/*.gz\"\n",
    "turbo_path_deed = \"/nfs/turbo/lib-data-corelogic/Data/deed/*.gz\"\n",
    "turbo_path_tax = \"/nfs/turbo/lib-data-corelogic/Data/tax/*.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ba4b9",
   "metadata": {},
   "source": [
    "The following command imports a set of partitioned CoreLogic data file into a dataframe (df). You can switch between foreclosures, deeds, and taxes by choosing the relevant path accordingly. In each text file, the pipe ```|``` was used as a delimiter and is set  in the ```sep``` argument as such.\n",
    "\n",
    "__A note on import speeds__: Because of their size, it takes a little while to read in each partitioned data file collection (foreclosures about 50 seconds, taxes about 4.5 minutes, deeds about 3.5 minutes). Importing the raw data files takes much longer, e.g., foreclosures about 6.5 minutes. Using the pre-processed data from CSCAR greatly improves import speeds as Spark can spread computation across multiple cores.\n",
    "\n",
    "Let's work with the deed data for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5904b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(turbo_path_deed, inferSchema=True, header=True, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3058a25",
   "metadata": {},
   "source": [
    "Let's explore the data a bit. We want to know how many rows and columns there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951a0324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367782480, 97)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns))) ## print number of rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e508e",
   "metadata": {},
   "source": [
    "Let's get the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3ac646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FIPS',\n",
       " 'APN (Parcel Number) (unformatted)',\n",
       " 'PCL ID IRIS FORMATTED',\n",
       " 'APN SEQUENCE NUMBER',\n",
       " 'PENDING RECORD INDICATOR',\n",
       " 'CORPORATE INDICATOR',\n",
       " 'OWNER FULL NAME',\n",
       " 'OWNER 1 LAST NAME',\n",
       " 'OWNER 1 FIRST NAME & M I',\n",
       " 'OWNER 2 LAST NAME',\n",
       " 'OWNER 2 FIRST NAME & MI',\n",
       " 'OWNER ETAL INDICATOR',\n",
       " 'C/O NAME',\n",
       " 'OWNER RELATIONSHIP RIGHTS CODE',\n",
       " 'OWNER RELATIONSHIP TYPE',\n",
       " 'PARTIAL INTEREST INDICATOR',\n",
       " 'ABSENTEE OWNER STATUS',\n",
       " 'PROPERTY LEVEL LATITUDE',\n",
       " 'PROPERTY LEVEL LONGITUDE',\n",
       " 'SITUS HOUSE NUMBER PREFIX',\n",
       " 'SITUS HOUSE NUMBER',\n",
       " 'SITUS HOUSE NUMBER SUFFIX',\n",
       " 'SITUS DIRECTION',\n",
       " 'SITUS STREET NAME',\n",
       " 'SITUS MODE',\n",
       " 'SITUS QUADRANT',\n",
       " 'SITUS APARTMENT UNIT',\n",
       " 'SITUS CITY',\n",
       " 'SITUS STATE',\n",
       " 'SITUS ZIP CODE',\n",
       " 'SITUS CARRIER CODE',\n",
       " 'MAILING HOUSE NUMBER PREFIX',\n",
       " 'MAILING HOUSE NUMBER',\n",
       " 'MAILING HOUSE NUMBER SUFFIX',\n",
       " 'MAILING DIRECTION',\n",
       " 'MAILING STREET NAME',\n",
       " 'MAILING MODE',\n",
       " 'MAILING QUADRANT',\n",
       " 'MAILING APARTMENT UNIT',\n",
       " 'MAILING PROPERTY CITY',\n",
       " 'MAILING PROPERTY STATE',\n",
       " 'MAILING PROPERTY ADDRESS ZIP CODE',\n",
       " 'MAILING CARRIER CODE',\n",
       " 'BATCH-ID',\n",
       " 'BATCH-SEQ',\n",
       " 'MULTI APN',\n",
       " 'SELLER LAST NAME',\n",
       " 'SELLER FIRST NAME',\n",
       " 'SELLER NAME 1',\n",
       " 'SELLER NAME 2',\n",
       " 'SALE CODE',\n",
       " 'SALE AMOUNT',\n",
       " 'SALE DATE (YYYYMMDD)',\n",
       " 'RECORDING DATE (YYYYMMDD)',\n",
       " 'DOCUMENT TYPE',\n",
       " 'TRANSACTION TYPE',\n",
       " 'DOCUMENT NUMBER',\n",
       " 'BOOK/PAGE (6x6)',\n",
       " 'LENDER FULL NAME',\n",
       " 'LENDER LAST NAME',\n",
       " 'LENDER FIRST NAME',\n",
       " 'LENDER ADDRESS',\n",
       " 'LENDER CITY',\n",
       " 'LENDER ST',\n",
       " 'LENDER ZIP',\n",
       " 'LENDER COMPANY CODE',\n",
       " 'TITLE COMPANY NAME',\n",
       " 'TITLE COMPANY CODE',\n",
       " 'MORTGAGE AMOUNT',\n",
       " 'MORTGAGE DATE',\n",
       " 'MORTGAGE INTEREST RATE',\n",
       " 'MORTGAGE LOAN TYPE CODE',\n",
       " 'MORTGAGE DEED TYPE',\n",
       " 'MORTGAGE TERM CODE',\n",
       " 'MORTGAGE TERM',\n",
       " 'MORTGAGE DUE DATE',\n",
       " 'MORTGAGE ASSUMPTION AMOUNT',\n",
       " 'MTG SEQ NUMBER',\n",
       " 'PRI-CAT-CODE',\n",
       " 'MTG SEC CAT CODES 1X10',\n",
       " 'DEED SEC CAT CODES 2X10',\n",
       " 'OWNERSHIP TRANSFER PERCENTAGE',\n",
       " 'LAND USE',\n",
       " 'PROPERTY INDICATOR',\n",
       " 'SELLER CARRY BACK',\n",
       " 'INTER FAMILY',\n",
       " 'PRIVATE PARTY LENDER',\n",
       " 'MORTGAGE INTEREST RATE TYPE',\n",
       " 'CONSTRUCTION LOAN',\n",
       " 'RESALE/NEW CONSTRUCTION',\n",
       " 'FORECLOSURE',\n",
       " 'CASH/MORTGAGE PURCHASE',\n",
       " 'EQUITY FLAG',\n",
       " 'REFI FLAG',\n",
       " 'RESIDENTIAL MODEL INDICATOR',\n",
       " 'ADD/CHANGE FIELD',\n",
       " 'FILLER']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d157f56",
   "metadata": {},
   "source": [
    "Let's print a select few rows and columns of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22b0d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+--------------+\n",
      "| FIPS|SITUS CITY|SITUS STATE|SITUS ZIP CODE|\n",
      "+-----+----------+-----------+--------------+\n",
      "|12099|      null|       null|          null|\n",
      "|17097|      null|       null|          null|\n",
      "|97200|      null|       null|          null|\n",
      "|97200|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "|17097|      null|       null|          null|\n",
      "|97199|      null|       null|          null|\n",
      "+-----+----------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('FIPS', 'SITUS CITY', 'SITUS STATE', 'SITUS ZIP CODE').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cde04",
   "metadata": {},
   "source": [
    "Let's assume we wanted to filter the CoreLogic data only for Wayne county, MI. The FIPS code for Wayne county is '26163' ([source](https://mi.postcodebase.com/county/26163))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f4902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WayneCsubset = df.filter(df.FIPS==26163)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2467d87",
   "metadata": {},
   "source": [
    "Let's print a few rows and columns of the subset. As you can see, we are only dealing with Wayne county now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb6648b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+--------------+\n",
      "| FIPS|SITUS CITY|SITUS STATE|SITUS ZIP CODE|\n",
      "+-----+----------+-----------+--------------+\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "|26163|      null|       null|          null|\n",
      "+-----+----------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "WayneCsubset.select('FIPS', 'SITUS CITY', 'SITUS STATE', 'SITUS ZIP CODE').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb7ce7",
   "metadata": {},
   "source": [
    "How many rows are in the Wayne county subset? Use the count() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01514600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2190976"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WayneCsubset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a766ab9",
   "metadata": {},
   "source": [
    "There are many different cities within Wayne county. Let's get a list of all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61109f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SITUS CITY='LINCOLN PARK'),\n",
       " Row(SITUS CITY='MELVINDALE'),\n",
       " Row(SITUS CITY='NORTHVILLE'),\n",
       " Row(SITUS CITY='TRENTON'),\n",
       " Row(SITUS CITY='YPSILANTI'),\n",
       " Row(SITUS CITY='BELLEVILLE'),\n",
       " Row(SITUS CITY='OAK PARK'),\n",
       " Row(SITUS CITY=None),\n",
       " Row(SITUS CITY='RIVERVIEW'),\n",
       " Row(SITUS CITY='GROSSE POINTE WOODS'),\n",
       " Row(SITUS CITY='FLAT ROCK'),\n",
       " Row(SITUS CITY='GROSSE ILE'),\n",
       " Row(SITUS CITY='GROSSE POINTE PARK'),\n",
       " Row(SITUS CITY='WARREN'),\n",
       " Row(SITUS CITY='GIBRALTAR'),\n",
       " Row(SITUS CITY='GROSSE POINTE'),\n",
       " Row(SITUS CITY='MONROE'),\n",
       " Row(SITUS CITY='WYANDOTTE'),\n",
       " Row(SITUS CITY='HIGHLAND'),\n",
       " Row(SITUS CITY='WOODHAVEN'),\n",
       " Row(SITUS CITY='INKSTER'),\n",
       " Row(SITUS CITY='SOUTHGATE'),\n",
       " Row(SITUS CITY='SUMPTER TWP'),\n",
       " Row(SITUS CITY='GARDEN CITY'),\n",
       " Row(SITUS CITY='HIGHLAND PARK'),\n",
       " Row(SITUS CITY='DETROIT'),\n",
       " Row(SITUS CITY='FERNDALE'),\n",
       " Row(SITUS CITY='CHELSEA'),\n",
       " Row(SITUS CITY='BROWNSTOWN TWP'),\n",
       " Row(SITUS CITY='NEW HUDSON'),\n",
       " Row(SITUS CITY='LANSING'),\n",
       " Row(SITUS CITY='DEARBORN HEIGHTS'),\n",
       " Row(SITUS CITY='CANTON'),\n",
       " Row(SITUS CITY='DEARBORN'),\n",
       " Row(SITUS CITY='GROSSE POINTE SHORES'),\n",
       " Row(SITUS CITY='ROMULUS'),\n",
       " Row(SITUS CITY='BINGHAM FARMS'),\n",
       " Row(SITUS CITY='LIVONIA'),\n",
       " Row(SITUS CITY='RIVER ROUGE'),\n",
       " Row(SITUS CITY='VAN BUREN TWP'),\n",
       " Row(SITUS CITY='NEW BOSTON'),\n",
       " Row(SITUS CITY='WESTLAND'),\n",
       " Row(SITUS CITY='GROSSE POINTE FARMS'),\n",
       " Row(SITUS CITY='PLYMOUTH'),\n",
       " Row(SITUS CITY='BROWNSTOWN'),\n",
       " Row(SITUS CITY='REDFORD'),\n",
       " Row(SITUS CITY='WAYNE'),\n",
       " Row(SITUS CITY='HARPER WOODS'),\n",
       " Row(SITUS CITY='TAYLOR'),\n",
       " Row(SITUS CITY='CARLETON'),\n",
       " Row(SITUS CITY='ALLEN PARK'),\n",
       " Row(SITUS CITY='SOUTHFIELD'),\n",
       " Row(SITUS CITY='ECORSE'),\n",
       " Row(SITUS CITY='ROCKWOOD'),\n",
       " Row(SITUS CITY='BROWNSTOWN TOWNSHIP'),\n",
       " Row(SITUS CITY='HAMTRAMCK')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WayneCsubset.select('SITUS CITY').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842db83c",
   "metadata": {},
   "source": [
    "Let's create a subset for Detroit only. We will filter using the 'SITUS CITY' variable. This variables designates the city associated with the property address. \n",
    "\n",
    "Note that this is a straightforward filtering method if using the Wayne county subset we created previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd6c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit = WayneCsubset.filter(WayneCsubset[\"SITUS CITY\"]==\"DETROIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a19a40",
   "metadata": {},
   "source": [
    "If you wanted to create a Detroit subset from the entire dataset, we suggest filtering on 'SITUS CITY' and 'SITUS STATE'. When using the entire dataframe, filtering on 'SITUS CITY' alone could run into city name ambiguity across states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c54340b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit2 = df.filter((df[\"SITUS CITY\"]==\"DETROIT\") & (df[\"SITUS STATE\"]==\"MI\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294452ef",
   "metadata": {},
   "source": [
    "How many rows are in the Detroit subset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b4aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1129420"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detroit.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed95cf4",
   "metadata": {},
   "source": [
    "Do the two filtering methods yield the same number of rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf449eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detroit.count()==detroit2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb79a17",
   "metadata": {},
   "source": [
    "Ok, this is a problem. There might be an issue with missing values. This needs to be explored further (TODO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f3ce289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+--------------+\n",
      "| FIPS|SITUS CITY|SITUS STATE|SITUS ZIP CODE|\n",
      "+-----+----------+-----------+--------------+\n",
      "|26163|   DETROIT|         MI|     482013148|\n",
      "|26163|   DETROIT|         MI|     482013148|\n",
      "|26163|   DETROIT|         MI|     482013148|\n",
      "|26163|   DETROIT|         MI|     482013148|\n",
      "|26163|   DETROIT|         MI|     482012463|\n",
      "|26163|   DETROIT|         MI|         48202|\n",
      "|26163|   DETROIT|         MI|         48202|\n",
      "|26163|   DETROIT|         MI|         48202|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|     482022828|\n",
      "|26163|   DETROIT|         MI|         48202|\n",
      "|26163|   DETROIT|         MI|     482021302|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "|26163|   DETROIT|         MI|     482021368|\n",
      "+-----+----------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detroit.select('FIPS', 'SITUS CITY', 'SITUS STATE', 'SITUS ZIP CODE').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0e711",
   "metadata": {},
   "source": [
    "This looks like what we are interested in. Let's write the Detroit data to a new csv file in an ```output/``` folder in our ```home/[uniqname]/``` directory. (Note: You probably need to change this path, depending on where you store this notebook.) By default, Spark writes big data into multiple files to optimize computation times during import and export. This is recommended practice, especially if the data is big, i.e., if it has many rows and/or columns.\n",
    "\n",
    "The below command writes 100 partitions of the Detroit data to the designated folder. \n",
    "\n",
    "_Note_: If you saved data to this path before, you will need to add the argument ```overwrite=True``` to the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ab02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit.write.csv(\"../../output/corelogic_data_deeds_Detroit_partitioned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1bec64",
   "metadata": {},
   "source": [
    "There is also a way to force the data into one single file. Sometimes, a single file is needed to continue processing the data with other research software. Saving the data into one file is a little risky and might not always work, so caution is advised. \n",
    "\n",
    "The following command combines the data into one core (Caution: it is very slow). If the data does not fit, it will throw an error. _Note_: If you saved data to this path before, you will need to add the argument ```overwrite=True``` to the function call. The overwrite argument would overwrite the previously created ```output/``` directory.\n",
    "\n",
    "Note: You would only need to run this, if you indeed need only one single data file. Many research programs allow you to read in and combine multiple data files into one object. See for example the [glob method in Python](https://docs.python.org/3/library/glob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "detroit.coalesce(1).write.csv(\"../../output/corelogic_data_deeds_Detroit_singlefile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c58568",
   "metadata": {},
   "source": [
    "TODO: show how to draw and save just a sample of the Detroit data (n=1000) that is small enough to use for writing and testing code for analyzing the Detroit subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f403df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample and save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
